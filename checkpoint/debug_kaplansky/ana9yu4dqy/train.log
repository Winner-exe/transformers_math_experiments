INFO - 01/21/25 00:19:09 - 0:00:00 - ============ Initialized logger ============
INFO - 01/21/25 00:19:09 - 0:00:00 - batch_size: 32
                                     command: python C:\Users\Winston\Documents\Math-AI\transformers_math_experiments\fc_loop.py --num_initial_empty_objects=1000 --final_database_size=250 --target_db_size=1000 --sample-only=1000 --nb_threads=16 --nb_local_searches=160 --num-workers=8 --max-steps=2000 --max_epochs=3000 --seed=-1 --top-k=-1 --type=transformer --n-layer=4 --n-head=8 --n-embd=64 --n-embd2=32 --batch-size=32 --learning-rate=5e-4 --weight-decay=0.01 --max-output-length=1200 --gen_batch_size=2000 --n_tokens=100 --temperature=1.0 --dump_path=checkpoint --exp_name=debug_kaplansky --local_rank=-1 --master_port=-1 --debug_slurm=False --exp_id "ana9yu4dqy"
                                     cpu: False
                                     debug: False
                                     debug_slurm: False
                                     dump_path: checkpoint\debug_kaplansky\ana9yu4dqy
                                     exp_id: ana9yu4dqy
                                     exp_name: debug_kaplansky
                                     final_database_size: 250
                                     gen_batch_size: 2000
                                     global_rank: 0
                                     is_master: True
                                     is_slurm_job: False
                                     learning_rate: 0.0005
                                     local_rank: 0
                                     master_port: -1
                                     max_epochs: 3000
                                     max_output_length: 1200
                                     max_steps: 2000
                                     multi_gpu: False
                                     multi_node: False
                                     n_embd: 64
                                     n_embd2: 32
                                     n_gpu_per_node: 1
                                     n_head: 8
                                     n_layer: 4
                                     n_nodes: 1
                                     n_tokens: 100
                                     nb_local_searches: 160
                                     nb_threads: 16
                                     node_id: 0
                                     num_initial_empty_objects: 1000
                                     num_workers: 8
                                     sample_only: 1000
                                     seed: -1
                                     target_db_size: 1000
                                     temperature: 1.0
                                     top_k: -1
                                     type: transformer
                                     weight_decay: 0.01
                                     world_size: 1
INFO - 01/21/25 00:19:09 - 0:00:00 - The experiment will be stored in checkpoint\debug_kaplansky\ana9yu4dqy
                                     
INFO - 01/21/25 00:19:09 - 0:00:00 - Running command: python C:\Users\Winston\Documents\Math-AI\transformers_math_experiments\fc_loop.py --num_initial_empty_objects=1000 --final_database_size=250 --target_db_size=1000 --sample-only=1000 --nb_threads=16 --nb_local_searches=160 --num-workers=8 --max-steps=2000 --max_epochs=3000 --seed=-1 --top-k=-1 --type=transformer --n-layer=4 --n-head=8 --n-embd=64 --n-embd2=32 --batch-size=32 --learning-rate=5e-4 --weight-decay=0.01 --max-output-length=1200 --gen_batch_size=2000 --n_tokens=100 --temperature=1.0 --dump_path=checkpoint --exp_name=debug_kaplansky --local_rank=-1 --master_port=-1 --debug_slurm=False

INFO - 01/21/25 00:19:09 - 0:00:00 - seed: 440783435
INFO - 01/21/25 00:19:09 - 0:00:00 - JULIA_NUM_THREADS is set to 16
INFO - 01/21/25 00:22:00 - 0:02:51 - Created checkpoint\debug_kaplansky\ana9yu4dqy\temp.txt and training tokenizer...
INFO - 01/21/25 00:22:00 - 0:02:51 - Directory 'checkpoint\debug_kaplansky\ana9yu4dqy/tokenizer_data' created.
INFO - 01/21/25 00:22:00 - 0:02:51 - File 'checkpoint\debug_kaplansky\ana9yu4dqy\temp.txt' has been deleted.
INFO - 01/21/25 00:22:00 - 0:02:51 - 0 / 250
INFO - 01/21/25 00:22:00 - 0:02:52 - initializing at generation: 1
INFO - 01/21/25 00:22:00 - 0:02:52 - number of examples in the dataset: 250
INFO - 01/21/25 00:22:00 - 0:02:52 - max word length: 360
INFO - 01/21/25 00:22:00 - 0:02:52 - number of unique characters in the vocabulary: 5
INFO - 01/21/25 00:22:00 - 0:02:52 - vocabulary:
INFO - 01/21/25 00:22:00 - 0:02:52 - ['V0', 'V1', 'V2', 'V3', 'V4']
INFO - 01/21/25 00:22:00 - 0:02:52 - split up the dataset into 225 training examples and 25 test examples
INFO - 01/21/25 00:22:00 - 0:02:52 - dataset determined that: vocab_size=101, block_size=1201
INFO - 01/21/25 00:22:01 - 0:02:52 - model #params: 289856
INFO - 01/21/25 00:22:01 - 0:02:52 - ============ Start of generation 1 ============
INFO - 01/21/25 00:22:01 - 0:02:52 - Memory allocated:  23.12MB, reserved: 42.00MB
INFO - 01/21/25 00:22:01 - 0:02:52 - training
INFO - 01/21/25 00:22:31 - 0:03:22 - step 0 | loss 4.5745 | step time 14762.04ms
