INFO - 01/04/25 12:59:17 - 0:00:00 - ============ Initialized logger ============
INFO - 01/04/25 12:59:17 - 0:00:00 - batch_size: 64
                                     command: python C:\Users\Winston\Documents\Math-AI\transformers_math_experiments\fc_loop.py --exp_id "diqtq4aa4h"
                                     cpu: False
                                     debug: False
                                     debug_slurm: False
                                     dump_path: checkpoint\debug\diqtq4aa4h
                                     exp_id: diqtq4aa4h
                                     exp_name: debug
                                     final_database_size: 50000
                                     gen_batch_size: 1000
                                     global_rank: 0
                                     is_master: True
                                     is_slurm_job: False
                                     learning_rate: 0.0005
                                     local_rank: 0
                                     master_port: -1
                                     max_epochs: 30000
                                     max_output_length: 160
                                     max_steps: 20000
                                     multi_gpu: False
                                     multi_node: False
                                     n_embd: 64
                                     n_embd2: 32
                                     n_gpu_per_node: 1
                                     n_head: 8
                                     n_layer: 4
                                     n_nodes: 1
                                     n_tokens: 100
                                     nb_local_searches: 1200
                                     nb_threads: 1
                                     node_id: 0
                                     num_initial_empty_objects: 500000
                                     num_workers: 8
                                     sample_only: 500000
                                     seed: -1
                                     target_db_size: 500000
                                     temperature: 1.0
                                     top_k: -1
                                     type: transformer
                                     weight_decay: 0.01
                                     world_size: 1
INFO - 01/04/25 12:59:17 - 0:00:00 - The experiment will be stored in checkpoint\debug\diqtq4aa4h
                                     
INFO - 01/04/25 12:59:17 - 0:00:00 - Running command: python C:\Users\Winston\Documents\Math-AI\transformers_math_experiments\fc_loop.py

INFO - 01/04/25 12:59:17 - 0:00:00 - seed: 252038364
INFO - 01/04/25 12:59:17 - 0:00:00 - JULIA_NUM_THREADS is set to 1
INFO - 01/04/25 13:00:28 - 0:01:11 - Created checkpoint\debug\diqtq4aa4h\temp.txt and training tokenizer...
INFO - 01/04/25 13:00:28 - 0:01:11 - Directory 'checkpoint\debug\diqtq4aa4h/tokenizer_data' created.
INFO - 01/04/25 13:00:29 - 0:01:12 - File 'checkpoint\debug\diqtq4aa4h\temp.txt' has been deleted.
INFO - 01/04/25 13:00:29 - 0:01:12 - 0 / 50000
INFO - 01/04/25 13:00:30 - 0:01:12 - 10000 / 50000
INFO - 01/04/25 13:00:30 - 0:01:13 - 20000 / 50000
INFO - 01/04/25 13:00:30 - 0:01:13 - 30000 / 50000
INFO - 01/04/25 13:00:31 - 0:01:14 - 40000 / 50000
INFO - 01/04/25 13:00:31 - 0:01:14 - initializing at generation: 1
INFO - 01/04/25 13:00:32 - 0:01:14 - number of examples in the dataset: 50000
INFO - 01/04/25 13:00:32 - 0:01:14 - max word length: 41
INFO - 01/04/25 13:00:32 - 0:01:14 - number of unique characters in the vocabulary: 100
INFO - 01/04/25 13:00:32 - 0:01:14 - vocabulary:
INFO - 01/04/25 13:00:32 - 0:01:14 - ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99']
INFO - 01/04/25 13:00:32 - 0:01:14 - split up the dataset into 49000 training examples and 1000 test examples
INFO - 01/04/25 13:00:32 - 0:01:14 - dataset determined that: vocab_size=101, block_size=161
INFO - 01/04/25 13:00:32 - 0:01:15 - model #params: 223296
INFO - 01/04/25 13:00:32 - 0:01:15 - ============ Start of generation 1 ============
INFO - 01/04/25 13:00:32 - 0:01:15 - Memory allocated:  1.26MB, reserved: 2.00MB
INFO - 01/04/25 13:00:32 - 0:01:15 - training
INFO - 01/04/25 13:00:52 - 0:01:34 - step 0 | loss 4.7677 | step time 847.86ms
INFO - 01/04/25 13:00:58 - 0:01:41 - step 100 | loss 4.0014 | step time 60.15ms
INFO - 01/04/25 13:01:04 - 0:01:46 - step 200 | loss 3.8698 | step time 55.58ms
INFO - 01/04/25 13:01:09 - 0:01:52 - step 300 | loss 3.8868 | step time 56.31ms
INFO - 01/04/25 13:01:15 - 0:01:58 - step 400 | loss 3.8573 | step time 56.74ms
INFO - 01/04/25 13:01:21 - 0:02:04 - step 500 | loss 3.8301 | step time 59.03ms
INFO - 01/04/25 13:01:22 - 0:02:04 - step 500 train loss: 3.8038978576660156 test loss: 3.8213562965393066
INFO - 01/04/25 13:01:22 - 0:02:04 - test loss 3.8213562965393066 is the best so far, saving model to checkpoint\debug\diqtq4aa4h\model.pt
